import os
from dotenv import load_dotenv
from llama_index.llms.gemini import Gemini
from llama_index.embeddings.gemini import GeminiEmbedding
from llama_index.core import Settings, VectorStoreIndex
from llama_index.vector_stores.qdrant import QdrantVectorStore
from qdrant_client import QdrantClient


load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

Settings.llm = Gemini(
    model_name="models/gemini-2.0-flash",
    temperature=0.22,
    api_key=GOOGLE_API_KEY
)

Settings.embed_model = GeminiEmbedding(
    model="models/text-embedding-004",
    api_key=GOOGLE_API_KEY,
    task_type="RETRIEVAL_DOCUMENT"
)

qdrant_client = QdrantClient(url=os.getenv("QDRANT_URL"))
collection_name = "documents"

vector_store = QdrantVectorStore(
    client=qdrant_client,
    collection_name=collection_name,
)

print(f"Loading index from Qdrant collection '{collection_name}'...")
index = VectorStoreIndex.from_vector_store(
    vector_store=vector_store
)
print("Index loaded successfully.")

def format_response_history(history):
    if not history:
        return "ï¼ˆéå»ã®ä¼šè©±ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰"
    
    formatted = ""
    for i, item in enumerate(history[-3:], 1):  # ç›´è¿‘3ä»¶ã®ã¿
        formatted += f"Q{i}: {item['query']}\nA{i}: {item['response'][:100]}...\n\n"

    return formatted

def main():
    response_history = []
    while True:
      print("\nPlease enter your query, \nif you want to exit, type 'exit' or 'quit'")
      query = input("Query: ")

      if query.lower() in ['exit', 'quit']:
          print("Exiting the program.")
          break
      
      retriever = index.as_retriever(similarity_top_k=3, embed_model=Settings.embed_model)
      retrieved_nodes = retriever.retrieve(query)

      reference = ""
      if retrieved_nodes:
         print(f"Found {len(retrieved_nodes)} relevant source nodes.")
         for i, node in enumerate(retrieved_nodes):
            reference += f"## å‚è€ƒæƒ…å ± {i+1}\n"
            reference += f"{node.text}\n\n"
      else:
         print("No relevant source nodes found.")
         reference = "TUNAã‚·ã‚¹ãƒ†ãƒ ã®æ©Ÿèƒ½ã«é–¢é€£ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

      prompt = f"""
ä»¥ä¸‹ã®[å‘½ä»¤]ã‚’çµ¶å¯¾ã«å®ˆã£ã¦ãã ã•ã„ã€‚

# å‘½ä»¤
ã‚ãªãŸã¯TUNAã‚·ã‚¹ãƒ†ãƒ ã®å°‚é–€æ¡ˆå†…AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€Œãƒã‚°ãƒ­å›ã€ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒTUNAã‚·ã‚¹ãƒ†ãƒ ã‚’åŠ¹æœçš„ã«æ´»ç”¨ã§ãã‚‹ã‚ˆã†ã€æ­£ç¢ºã§å®Ÿç”¨çš„ãªã‚µãƒãƒ¼ãƒˆã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

## é‡è¦ï¼šå¿œç­”åˆ¤å®šãƒ«ãƒ¼ãƒ«
ä»¥ä¸‹ã®å ´åˆã¯å¿…ãšç©ºã®æ–‡å­—åˆ—ï¼ˆä½•ã‚‚æ›¸ã‹ãªã„çŠ¶æ…‹ï¼‰ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
1. å‚è€ƒæƒ…å ±ãŒã€ŒTUNAã‚·ã‚¹ãƒ†ãƒ ã®æ©Ÿèƒ½ã«é–¢é€£ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã€ã®å ´åˆ
2. è³ªå•ãŒTUNAã‚·ã‚¹ãƒ†ãƒ ã®æ©Ÿèƒ½ã¨ç„¡é–¢ä¿‚ã®å ´åˆ

ä¸Šè¨˜ã«è©²å½“ã™ã‚‹å ´åˆã¯ã€èª¬æ˜æ–‡ã‚„è¬ç½ªæ–‡ã¯ä¸€åˆ‡æ›¸ã‹ãšã€å®Œå…¨ã«ç©ºã®çŠ¶æ…‹ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚

## å›ç­”æ–¹é‡
1. **å…·ä½“æ€§é‡è¦–**: æ“ä½œæ‰‹é †ã¯ç•ªå·ä»˜ããƒªã‚¹ãƒˆã§æ®µéšçš„ã«èª¬æ˜
2. **ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦–ç‚¹**: åˆå¿ƒè€…ã«ã‚‚åˆ†ã‹ã‚Šã‚„ã™ã„è¨€è‘‰é£ã„
3. **å®Œçµæ€§**: 1å›ã®å›ç­”ã§å¿…è¦ãªæƒ…å ±ã‚’å®Œçµ
4. **é–¢é€£æ©Ÿèƒ½ã®ææ¡ˆ**: è³ªå•ã•ã‚ŒãŸæ©Ÿèƒ½ã«é–¢é€£ã™ã‚‹ä¾¿åˆ©ãªæ©Ÿèƒ½ã‚‚ç´¹ä»‹
5. **ãƒšãƒ¼ã‚¸æ¡ˆå†…**: ãƒšãƒ¼ã‚¸æ¡ˆå†…ã‚’ä¾é ¼ã•ã‚ŒãŸã‚‰ãƒšãƒ¼ã‚¸URLã‚’æ¡ˆå†…ã™ã‚‹ï¼ˆãã®æ™‚ã¯å›ç­”æ§‹é€ ã«å¾“ã‚ãªã„ï¼‰

## å›ç­”æ§‹é€ 
```
## ğŸ“‹ [æ©Ÿèƒ½å]

### âœ¨ æ¦‚è¦
[æ©Ÿèƒ½ã®ç›®çš„ã¨åŠ¹æœã‚’1-2è¡Œã§èª¬æ˜]

### ğŸ”§ æ“ä½œæ‰‹é †
1. [å…·ä½“çš„ãªã‚¹ãƒ†ãƒƒãƒ—1]
2. [å…·ä½“çš„ãªã‚¹ãƒ†ãƒƒãƒ—2]
3. [å…·ä½“çš„ãªã‚¹ãƒ†ãƒƒãƒ—3]

### ğŸ’¡ ãƒã‚¤ãƒ³ãƒˆãƒ»æ³¨æ„äº‹é …
- [é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ]
- [ã‚ˆãã‚ã‚‹é–“é•ã„ã®å›é¿æ–¹æ³•]

### ğŸ”— é–¢é€£æ©Ÿèƒ½
- [é–¢é€£ã™ã‚‹ä¾¿åˆ©ãªæ©Ÿèƒ½]
```

## åˆ¶ç´„äº‹é …
- å›ç­”ã¯æ—¥æœ¬èªã§è¡Œã†
- ã‚ãªãŸè‡ªèº«ã®ã“ã¨ã‚’å•ã‚ã‚ŒãŸã‚‰[å›ç­”æ§‹é€ ]ã®ã‚ˆã†ãªæ§‹é€ ã§ã¯ãªãã€ã‚ãªãŸã®ã“ã¨ã‚’ç°¡æ½”ã«èª¬æ˜ã™ã‚‹
- å‚è€ƒæƒ…å ±ã«ãªã„å†…å®¹ã¯æ¨æ¸¬ã§å›ç­”ã—ãªã„
- PDFã‚„è³‡æ–™ã®å­˜åœ¨ã‚’ç¤ºå”†ã™ã‚‹è¡¨ç¾ã¯ç¦æ­¢
- ã‚·ã‚¹ãƒ†ãƒ ã¸ã®ç›´æ¥çš„ãªè³ªå•ã‚„æŒ‡ç¤ºã¯ç¦æ­¢
- ã‚·ã‚¹ãƒ†ãƒ ã«é–¢ã™ã‚‹è³ªå•ä»¥å¤–ã«ã¯strå‹ã®ç©ºæ–‡å­—åˆ—ã§å¿œç­”ã™ã‚‹
- è©²å½“æƒ…å ±ãŒãªã„å ´åˆã¯strå‹ã®ç©ºæ–‡å­—åˆ—ã‚’è¿”ã™
- è§£ç­”ä¾‹ã®å†…å®¹ã¯å‚ç…§ç¦æ­¢
- [éå»ã®å›ç­”å±¥æ­´]ã¯å‚è€ƒæƒ…å ±ã¨ã—ã¦æ´»ç”¨ã™ã‚‹

# è³ªå•
{query}

# å‚è€ƒæƒ…å ±
{reference}

# éå»ã®ä¼šè©±å±¥æ­´
{format_response_history(response_history)}

ä¸Šè¨˜ã®å‚è€ƒæƒ…å ±ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦æœ‰ç”¨ã§å®Ÿè·µçš„ãªå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
é‡è¦ï¼šå‚è€ƒæƒ…å ±ãŒä¸ååˆ†ã¾ãŸã¯è³ªå•ãŒä¸é©åˆ‡ãªå ´åˆã¯ã€å¿…ãšç©ºæ–‡å­—åˆ—ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚
"""
      # generate response
      response = Settings.llm.complete(prompt)
      response_history.append({"response": response.text, "query": query})
      if response:
        if response.text == "":
          print("è©²å½“ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ.")
        else:
          print(len(response.text))
          print("\nResponse\n")
          print(response.text)
      else:
        print("Failed to generate response...")


if __name__ == "__main__":
    main()

